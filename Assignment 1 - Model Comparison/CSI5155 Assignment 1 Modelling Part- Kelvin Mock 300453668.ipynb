{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3658a940",
   "metadata": {},
   "source": [
    "# CSI5155 Machine Learning Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e685e",
   "metadata": {},
   "source": [
    "This notebook is only for building the machine learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd65ef5a",
   "metadata": {},
   "source": [
    "## Installing Prerequisites and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73d4542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kelvi\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kelvi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\users\\kelvi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install joblib\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e483b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import constants;\n",
    "from models import Models;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "import random;\n",
    "from fileOrganizer import organize, unpack;\n",
    "import joblib; # for saving Python objects (like models) in .pkl format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91001d66",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58dba1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>...</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>semer</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL5</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>...</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL6</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      age   gender  education  country  ethnicity   nscore   escore  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "       oscore   ascore  ...  ecstasy  heroin  ketamine legalh  lsd meth  \\\n",
       "0    -0.58331 -0.91699  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
       "1     1.43533  0.76096  ...      CL4     CL0       CL2    CL0  CL2  CL3   \n",
       "2    -0.84732 -1.62090  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
       "3    -0.01928  0.59042  ...      CL0     CL0       CL2    CL0  CL0  CL0   \n",
       "4    -0.45174 -0.30172  ...      CL1     CL0       CL0    CL1  CL0  CL0   \n",
       "...       ...      ...  ...      ...     ...       ...    ...  ...  ...   \n",
       "1880  1.88511  0.76096  ...      CL0     CL0       CL0    CL3  CL3  CL0   \n",
       "1881  0.58331  0.76096  ...      CL2     CL0       CL0    CL3  CL5  CL4   \n",
       "1882 -1.27553 -1.77200  ...      CL4     CL0       CL2    CL0  CL2  CL0   \n",
       "1883  0.29338 -1.62090  ...      CL3     CL0       CL0    CL3  CL3  CL0   \n",
       "1884  1.65653  1.11406  ...      CL3     CL0       CL0    CL3  CL3  CL0   \n",
       "\n",
       "     mushrooms nicotine semer  vsa  \n",
       "0          CL0      CL2   CL0  CL0  \n",
       "1          CL0      CL4   CL0  CL0  \n",
       "2          CL1      CL0   CL0  CL0  \n",
       "3          CL0      CL2   CL0  CL0  \n",
       "4          CL2      CL2   CL0  CL0  \n",
       "...        ...      ...   ...  ...  \n",
       "1880       CL0      CL0   CL0  CL5  \n",
       "1881       CL4      CL5   CL0  CL0  \n",
       "1882       CL2      CL6   CL0  CL0  \n",
       "1883       CL3      CL4   CL0  CL0  \n",
       "1884       CL3      CL6   CL0  CL2  \n",
       "\n",
       "[1885 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('drug_consumption.data', sep=',', header=None, names=constants.column_names_orig);\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87747b8d",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The original dataset consists of 1885 instances. \n",
    "- Each of which has 32 features in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71958263",
   "metadata": {},
   "source": [
    "## Handling Data in the dataset to match with our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee44c9",
   "metadata": {},
   "source": [
    "### Group and Convert multiple categories into 2 unique categories (for the binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b20f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>...</th>\n",
       "      <th>ecstasy</th>\n",
       "      <th>heroin</th>\n",
       "      <th>ketamine</th>\n",
       "      <th>legalh</th>\n",
       "      <th>lsd</th>\n",
       "      <th>meth</th>\n",
       "      <th>mushrooms</th>\n",
       "      <th>nicotine</th>\n",
       "      <th>semer</th>\n",
       "      <th>vsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>...</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>...</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>...</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>non-user</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      age   gender  education  country  ethnicity   nscore   escore  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "       oscore   ascore  ...   ecstasy    heroin  ketamine    legalh       lsd  \\\n",
       "0    -0.58331 -0.91699  ...  non-user  non-user  non-user  non-user  non-user   \n",
       "1     1.43533  0.76096  ...      user  non-user      user  non-user      user   \n",
       "2    -0.84732 -1.62090  ...  non-user  non-user  non-user  non-user  non-user   \n",
       "3    -0.01928  0.59042  ...  non-user  non-user      user  non-user  non-user   \n",
       "4    -0.45174 -0.30172  ...  non-user  non-user  non-user  non-user  non-user   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1880  1.88511  0.76096  ...  non-user  non-user  non-user      user      user   \n",
       "1881  0.58331  0.76096  ...      user  non-user  non-user      user      user   \n",
       "1882 -1.27553 -1.77200  ...      user  non-user      user  non-user      user   \n",
       "1883  0.29338 -1.62090  ...      user  non-user  non-user      user      user   \n",
       "1884  1.65653  1.11406  ...      user  non-user  non-user      user      user   \n",
       "\n",
       "          meth mushrooms  nicotine     semer       vsa  \n",
       "0     non-user  non-user      user  non-user  non-user  \n",
       "1         user  non-user      user  non-user  non-user  \n",
       "2     non-user  non-user  non-user  non-user  non-user  \n",
       "3     non-user  non-user      user  non-user  non-user  \n",
       "4     non-user      user      user  non-user  non-user  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1880  non-user  non-user  non-user  non-user      user  \n",
       "1881      user      user      user  non-user  non-user  \n",
       "1882  non-user      user      user  non-user  non-user  \n",
       "1883  non-user      user      user  non-user  non-user  \n",
       "1884  non-user      user      user  non-user      user  \n",
       "\n",
       "[1885 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_types = ['int64', 'float64'];\n",
    "for i in df_all.columns:\n",
    "    if (df_all[i].dtype not in num_types):\n",
    "        df_all[i] = df_all[i].apply(lambda x: \"non-user\" if int(x.replace(\"CL\", \"\")) <= 1 else \"user\");\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a7e3c5",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- All categorical fields (which represents whether the person has taken that drug before) has been replaced with values suitable for  a binary classfication problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22bf13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modified DataFrame into a new .csv file\n",
    "df_all.to_csv('drug_consumption.modified', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9dc38",
   "metadata": {},
   "source": [
    "### Construct 2 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35833f39",
   "metadata": {},
   "source": [
    "#### People who consume Chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4e77bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'age',\n",
       " 'gender',\n",
       " 'education',\n",
       " 'country',\n",
       " 'ethnicity',\n",
       " 'nscore',\n",
       " 'escore',\n",
       " 'oscore',\n",
       " 'ascore',\n",
       " 'cscore',\n",
       " 'impuslive',\n",
       " 'ss',\n",
       " 'choc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find a list of column names in consideration\n",
    "cols = [];\n",
    "for i in df_all.columns:\n",
    "    if (df_all[i].dtype in num_types):\n",
    "        cols.append(i);\n",
    "cols.append(constants.choco_dataset);\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0748fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>impuslive</th>\n",
       "      <th>ss</th>\n",
       "      <th>choc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      age   gender  education  country  ethnicity   nscore   escore  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "       oscore   ascore   cscore  impuslive       ss  choc  \n",
       "0    -0.58331 -0.91699 -0.00665   -0.21712 -1.18084  user  \n",
       "1     1.43533  0.76096 -0.14277   -0.71126 -0.21575  user  \n",
       "2    -0.84732 -1.62090 -1.01450   -1.37983  0.40148  user  \n",
       "3    -0.01928  0.59042  0.58489   -1.37983 -1.18084  user  \n",
       "4    -0.45174 -0.30172  1.30612   -0.21712 -0.21575  user  \n",
       "...       ...      ...      ...        ...      ...   ...  \n",
       "1880  1.88511  0.76096 -1.13788    0.88113  1.92173  user  \n",
       "1881  0.58331  0.76096 -1.51840    0.88113  0.76540  user  \n",
       "1882 -1.27553 -1.77200 -1.38502    0.52975 -0.52593  user  \n",
       "1883  0.29338 -1.62090 -2.57309    1.29221  1.22470  user  \n",
       "1884  1.65653  1.11406  0.41594    0.88113  1.22470  user  \n",
       "\n",
       "[1885 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_choco = df_all[cols];\n",
    "df_dataset_choco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9274b99",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- We have 14 features in consideration in the first dataset.\n",
    "- Meanwhile, the number of instances remains unchanged. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc904a",
   "metadata": {},
   "source": [
    "#### People who consume Magic Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40db946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'age',\n",
       " 'gender',\n",
       " 'education',\n",
       " 'country',\n",
       " 'ethnicity',\n",
       " 'nscore',\n",
       " 'escore',\n",
       " 'oscore',\n",
       " 'ascore',\n",
       " 'cscore',\n",
       " 'impuslive',\n",
       " 'ss',\n",
       " 'mushrooms']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find a list of column names in consideration\n",
    "cols = [];\n",
    "for i in df_all.columns:\n",
    "    if (df_all[i].dtype in num_types):\n",
    "        cols.append(i);\n",
    "cols.append(constants.mushrooms_dataset);\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bff59d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>nscore</th>\n",
       "      <th>escore</th>\n",
       "      <th>oscore</th>\n",
       "      <th>ascore</th>\n",
       "      <th>cscore</th>\n",
       "      <th>impuslive</th>\n",
       "      <th>ss</th>\n",
       "      <th>mushrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>non-user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1885</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>1886</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>0.45468</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1887</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>-0.57009</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1888</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.61113</td>\n",
       "      <td>0.21128</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      age   gender  education  country  ethnicity   nscore   escore  \\\n",
       "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
       "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
       "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
       "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
       "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
       "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
       "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
       "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
       "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
       "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
       "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
       "\n",
       "       oscore   ascore   cscore  impuslive       ss mushrooms  \n",
       "0    -0.58331 -0.91699 -0.00665   -0.21712 -1.18084  non-user  \n",
       "1     1.43533  0.76096 -0.14277   -0.71126 -0.21575  non-user  \n",
       "2    -0.84732 -1.62090 -1.01450   -1.37983  0.40148  non-user  \n",
       "3    -0.01928  0.59042  0.58489   -1.37983 -1.18084  non-user  \n",
       "4    -0.45174 -0.30172  1.30612   -0.21712 -0.21575      user  \n",
       "...       ...      ...      ...        ...      ...       ...  \n",
       "1880  1.88511  0.76096 -1.13788    0.88113  1.92173  non-user  \n",
       "1881  0.58331  0.76096 -1.51840    0.88113  0.76540      user  \n",
       "1882 -1.27553 -1.77200 -1.38502    0.52975 -0.52593      user  \n",
       "1883  0.29338 -1.62090 -2.57309    1.29221  1.22470      user  \n",
       "1884  1.65653  1.11406  0.41594    0.88113  1.22470      user  \n",
       "\n",
       "[1885 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_mushrooms = df_all[cols];\n",
    "df_dataset_mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf7ba3",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- We have 14 features in consideration in the second dataset.\n",
    "- Meanwhile, the number of instances also remains unchanged. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48e15e",
   "metadata": {},
   "source": [
    "## A. Machine Learning - Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64efab73",
   "metadata": {},
   "source": [
    "### Classification task for Chocolate users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1aac2",
   "metadata": {},
   "source": [
    "#### Load the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5f4c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decision tree': DecisionTreeClassifier(criterion='entropy', splitter='random'), 'random forest': RandomForestClassifier(criterion='entropy'), 'SVM': SVC(), 'gradient boosting': GradientBoostingClassifier(), 'multi-layer perceptron (MLP)': MLPClassifier(hidden_layer_sizes=3769, learning_rate='adaptive', max_iter=500), 'k‐nearest neighbour (k-NN) classifier': KNeighborsClassifier(n_jobs=-1, n_neighbors=7, weights='distance')}\n"
     ]
    }
   ],
   "source": [
    "chocoModels = Models();\n",
    "resChocoModels = chocoModels.getModels(\n",
    "    constants.descisionTree, # Single Decision Tree classifier\n",
    "    constants.randForest, # Random Forest classifier\n",
    "    constants.svm, # Support Vector Machine (SVM) classifier - SVC with RBF\n",
    "    constants.gradientBoost, # gradient boosting (GB) ensemble\n",
    "    constants.mlp, # multi-layer perceptron (MLP) classifier\n",
    "    constants.knn # k‐nearest neighbour (k-NN) classifier\n",
    ");\n",
    "print(resChocoModels);\n",
    "# save all models\n",
    "chocoModels.saveModels();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f1e18",
   "metadata": {},
   "source": [
    "#### Parameters Tuning - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6705fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune all models\n",
    "chocoModels.decisionTree_clf = Models.paramTuning(resChocoModels[constants.descisionTree]);\n",
    "chocoModels.randomForest_clf = Models.paramTuning(resChocoModels[constants.randForest]);\n",
    "chocoModels.svm_clf = Models.paramTuning(resChocoModels[constants.svm]);\n",
    "chocoModels.gradientBoost_clf = Models.paramTuning(resChocoModels[constants.gradientBoost]);\n",
    "chocoModels.mlp_clf = Models.paramTuning(resChocoModels[constants.mlp]);\n",
    "chocoModels.knn_clf = Models.paramTuning(resChocoModels[constants.knn]);\n",
    "# save the models\n",
    "chocoModels.saveModels(isTrained=False, dataset=constants.choco_dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598afddc",
   "metadata": {},
   "source": [
    "#### Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b1e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the Chocolate dataset: 1885\n",
      "Number of features in a sample: 13\n",
      "Number of Labels in the Chocolate dataset: 1885\n",
      "Unique Labels: ['non-user' 'user']\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to a numpy array\n",
    "np_samples_choco = df_dataset_choco.iloc[:, :-1].to_numpy();\n",
    "np_labels_choco = df_dataset_choco.iloc[:,-1].to_numpy();\n",
    "print(\"Number of samples in the Chocolate dataset: \" + str(len(np_samples_choco)));\n",
    "print(\"Number of features in a sample: \" + str(len(np_samples_choco[random.randint(0, len(np_samples_choco)-1)])));\n",
    "print(\"Number of Labels in the Chocolate dataset: \" + str(len(np_labels_choco)));\n",
    "print(\"Unique Labels: \" + str(np.unique(np_labels_choco)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06693dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for chocolate dataset: ['ID' 'age' 'gender' 'education' 'country' 'ethnicity' 'nscore' 'escore'\n",
      " 'oscore' 'ascore' 'cscore' 'impuslive' 'ss' 'choc']\n"
     ]
    }
   ],
   "source": [
    "columns_choco = df_dataset_choco.columns.to_numpy();\n",
    "print(f\"Columns for chocolate dataset: {columns_choco}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57df4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "choco_X_train, choco_X_test, choco_y_train, choco_y_test = train_test_split(\n",
    "    np_samples_choco,\n",
    "    np_labels_choco,\n",
    "    test_size=1/3,\n",
    "    stratify=np_labels_choco,\n",
    "    random_state=constants.random_state\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf486f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in the training set: 1256\n",
      "Number of Labels in the training set: 1256\n",
      "Unique Labels in the training set: ['non-user' 'user']\n",
      "Number of Samples in the test set: 629\n",
      "Number of Labels in the test set: 629\n",
      "Unique Labels in the test set: ['non-user' 'user']\n"
     ]
    }
   ],
   "source": [
    "# Verifying the Data\n",
    "print(\"Number of Samples in the training set: \" + str(len(choco_X_train)));\n",
    "print(\"Number of Labels in the training set: \" + str(len(choco_y_train)));\n",
    "print(\"Unique Labels in the training set: \" + str(np.unique(choco_y_train)));\n",
    "\n",
    "print(\"Number of Samples in the test set: \" + str(len(choco_X_test)));\n",
    "print(\"Number of Labels in the test set: \" + str(len(choco_y_test)));\n",
    "print(\"Unique Labels in the test set: \" + str(np.unique(choco_y_test)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5903aea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Verify whether the sizes of training set and the test set add up to the total size of the dataset\n",
    "print(len(choco_X_train) + len(choco_X_test) == len(df_dataset_choco.to_numpy()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999496d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing data for Chocolate dataset\n",
    "joblib.dump(choco_X_train, constants.choco_dataset + '_train-set_samples.pkl');\n",
    "joblib.dump(choco_y_train, constants.choco_dataset + '_train-set_labels.pkl');\n",
    "joblib.dump(choco_X_test, constants.choco_dataset + '_test-set_samples.pkl');\n",
    "joblib.dump(choco_y_test, constants.choco_dataset + '_test-set_labels.pkl');\n",
    "# Save the columns array\n",
    "# Note: We don't use the first ID column and the last labels column\n",
    "joblib.dump(columns_choco[1:-1], constants.choco_dataset + \"_columns.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee995a6",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- We successfully split the dataset into a training set and a test set,\n",
    "- with the same number of samples and labels in each set, \n",
    "-  and reserving all possible labels from the dataset correctly.\n",
    "- Meanwhile, the splitting did not trim or remove any data records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38412d7b",
   "metadata": {},
   "source": [
    "#### Train each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee48cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training data into models\n",
    "chocoModels.set_X_train(choco_X_train);\n",
    "chocoModels.set_y_train(choco_y_train);\n",
    "# Set the testing data into models\n",
    "chocoModels.set_X_test(choco_X_test);\n",
    "chocoModels.set_y_test(choco_y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c4e18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data from training set and testing set respectively\n",
    "chocoModels.normalize();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d379079",
   "metadata": {},
   "source": [
    "#### Save the Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59089074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing data for Chocolate dataset\n",
    "joblib.dump(choco_X_train, constants.choco_dataset + '_train-set_samples_normalized.pkl');\n",
    "joblib.dump(choco_y_train, constants.choco_dataset + '_train-set_labels_normalized.pkl');\n",
    "joblib.dump(choco_X_test, constants.choco_dataset + '_test-set_samples_normalized.pkl');\n",
    "joblib.dump(choco_y_test, constants.choco_dataset + '_test-set_labels_normalized.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f071f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training all models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models are completely trained.\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "chocoModels.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8ff3a",
   "metadata": {},
   "source": [
    "### Classification task for Magic Mushroom users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbf57a",
   "metadata": {},
   "source": [
    "#### Load the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd9d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decision tree': DecisionTreeClassifier(criterion='entropy', splitter='random'), 'random forest': RandomForestClassifier(criterion='entropy'), 'SVM': SVC(), 'gradient boosting': GradientBoostingClassifier(), 'multi-layer perceptron (MLP)': MLPClassifier(hidden_layer_sizes=3769, learning_rate='adaptive', max_iter=500), 'k‐nearest neighbour (k-NN) classifier': KNeighborsClassifier(n_jobs=-1, n_neighbors=7, weights='distance')}\n"
     ]
    }
   ],
   "source": [
    "mushModels = Models();\n",
    "resMushModels = mushModels.getModels(\n",
    "    constants.descisionTree, # Single Decision Tree classifier\n",
    "    constants.randForest, # Random Forest classifier\n",
    "    constants.svm, # Support Vector Machine (SVM) classifier - SVC with RBF\n",
    "    constants.gradientBoost, # gradient boosting (GB) ensemble\n",
    "    constants.mlp, # multi-layer perceptron (MLP) classifier\n",
    "    constants.knn # k‐nearest neighbour (k-NN) classifier\n",
    ");\n",
    "print(resMushModels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33f68f",
   "metadata": {},
   "source": [
    "#### Parameters Tuning - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4deeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune all models\n",
    "mushModels.decisionTree_clf = Models.paramTuning(resMushModels[constants.descisionTree]);\n",
    "mushModels.randomForest_clf = Models.paramTuning(resMushModels[constants.randForest]);\n",
    "mushModels.svm_clf = Models.paramTuning(resMushModels[constants.svm]);\n",
    "mushModels.gradientBoost_clf = Models.paramTuning(resMushModels[constants.gradientBoost]);\n",
    "mushModels.mlp_clf = Models.paramTuning(resMushModels[constants.mlp]);\n",
    "mushModels.knn_clf = Models.paramTuning(resMushModels[constants.knn]);\n",
    "# save the models\n",
    "mushModels.saveModels(isTrained=False, dataset=constants.mushrooms_dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b688f1",
   "metadata": {},
   "source": [
    "#### Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd7be312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the Chocolate dataset: 1885\n",
      "Number of features in a sample: 12\n",
      "Number of Labels in the Chocolate dataset: 1885\n",
      "Unique Labels: ['non-user' 'user']\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to a numpy array\n",
    "np_samples_mush = df_dataset_mushrooms.iloc[:, 1:-1].to_numpy();\n",
    "np_labels_mush = df_dataset_mushrooms.iloc[:,-1].to_numpy();\n",
    "print(\"Number of samples in the Chocolate dataset: \" + str(len(np_samples_mush)));\n",
    "print(\"Number of features in a sample: \" + str(len(np_samples_mush[random.randint(0, len(np_samples_mush)-1)])));\n",
    "print(\"Number of Labels in the Chocolate dataset: \" + str(len(np_labels_mush)));\n",
    "print(\"Unique Labels: \" + str(np.unique(np_labels_mush)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd9dfac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for mushroom dataset: ['ID' 'age' 'gender' 'education' 'country' 'ethnicity' 'nscore' 'escore'\n",
      " 'oscore' 'ascore' 'cscore' 'impuslive' 'ss' 'mushrooms']\n"
     ]
    }
   ],
   "source": [
    "columns_mush = df_dataset_mushrooms.columns.to_numpy();\n",
    "print(f\"Columns for mushroom dataset: {columns_mush}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c93388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "mush_X_train, mush_X_test, mush_y_train, mush_y_test = train_test_split(\n",
    "    np_samples_mush,\n",
    "    np_labels_mush,\n",
    "    test_size=1/3,\n",
    "    stratify=np_labels_mush,\n",
    "    random_state=constants.random_state\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bda8997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in the training set: 1256\n",
      "Number of Labels in the training set: 1256\n",
      "Unique Labels in the training set: ['non-user' 'user']\n",
      "Number of Samples in the test set: 629\n",
      "Number of Labels in the test set: 629\n",
      "Unique Labels in the test set: ['non-user' 'user']\n"
     ]
    }
   ],
   "source": [
    "# Verifying the Data\n",
    "print(\"Number of Samples in the training set: \" + str(len(mush_X_train)));\n",
    "print(\"Number of Labels in the training set: \" + str(len(mush_y_train)));\n",
    "print(\"Unique Labels in the training set: \" + str(np.unique(mush_y_train)));\n",
    "\n",
    "print(\"Number of Samples in the test set: \" + str(len(mush_X_test)));\n",
    "print(\"Number of Labels in the test set: \" + str(len(mush_y_test)));\n",
    "print(\"Unique Labels in the test set: \" + str(np.unique(mush_y_test)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6be435e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Verify whether the sizes of training set and the test set add up to the total size of the dataset\n",
    "print(len(mush_X_train) + len(mush_X_test) == len(df_dataset_mushrooms.to_numpy()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c736cbd0",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- We successfully split the dataset into a training set and a test set,\n",
    "- with the same number of samples and labels in each set, \n",
    "-  and reserving all possible labels from the dataset correctly.\n",
    "- Meanwhile, the splitting did not trim or remove any data records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16097b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing data for Chocolate dataset\n",
    "joblib.dump(mush_X_train, constants.mushrooms_dataset + '_train-set_samples.pkl');\n",
    "joblib.dump(mush_y_train, constants.mushrooms_dataset + '_train-set_labels.pkl');\n",
    "joblib.dump(mush_X_test, constants.mushrooms_dataset + '_test-set_samples.pkl');\n",
    "joblib.dump(mush_y_test, constants.mushrooms_dataset + '_test-set_labels.pkl');\n",
    "# Save the column names\n",
    "# Note: We don't use the first ID column and the last labels column\n",
    "joblib.dump(columns_mush[1:-1], constants.mushrooms_dataset + \"_columns.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f6278",
   "metadata": {},
   "source": [
    "#### Train each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c9582e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training data into models\n",
    "mushModels.set_X_train(mush_X_train);\n",
    "mushModels.set_y_train(mush_y_train);\n",
    "# Set the testing data into models\n",
    "mushModels.set_X_test(mush_X_test);\n",
    "mushModels.set_y_test(mush_y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28386b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data from training set and testing set respectively\n",
    "mushModels.normalize();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f51860",
   "metadata": {},
   "source": [
    "#### Save the Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f520deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing data for Chocolate dataset\n",
    "joblib.dump(mush_X_train, constants.mushrooms_dataset + '_train-set_samples_normalized.pkl');\n",
    "joblib.dump(mush_y_train, constants.mushrooms_dataset + '_train-set_labels_normalized.pkl');\n",
    "joblib.dump(mush_X_test, constants.mushrooms_dataset + '_test-set_samples_normalized.pkl');\n",
    "joblib.dump(mush_y_test, constants.mushrooms_dataset + '_test-set_labels_normalized.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bc046c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training all models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kelvi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models are completely trained.\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "mushModels.train(dataset=constants.mushrooms_dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdfd305",
   "metadata": {},
   "source": [
    "After training the classifiers with the both datasets, some files were exported. Hence, we arrange the, in proper file organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41707274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved choc_columns.pkl to ./choc\\Test Set\n",
      "Moved choc_model_decisionTree_posttrained.pkl to ./choc\\posttrained\n",
      "Moved choc_model_decisionTree_pretrained.pkl to ./choc\\pretrained\n",
      "Moved choc_model_Gradient_Boosting_posttrained.pkl to ./choc\\posttrained\n",
      "Moved choc_model_Gradient_Boosting_pretrained.pkl to ./choc\\pretrained\n",
      "Moved choc_model_KNN_posttrained.pkl to ./choc\\posttrained\n",
      "Moved choc_model_KNN_pretrained.pkl to ./choc\\pretrained\n",
      "Moved choc_model_MLP_posttrained.pkl to ./choc\\posttrained\n",
      "Moved choc_model_MLP_pretrained.pkl to ./choc\\pretrained\n",
      "Moved choc_model_randomForest_posttrained.pkl to ./choc\\posttrained\n",
      "Moved choc_model_randomForest_pretrained.pkl to ./choc\\pretrained\n",
      "Moved choc_model_SVC_RBF_posttrained.pkl to ./choc\\posttrained\n",
      "Moved choc_model_SVC_RBF_pretrained.pkl to ./choc\\pretrained\n",
      "Moved choc_test-set_labels.pkl to ./choc\\Test Set\n",
      "Moved choc_test-set_labels_normalized.pkl to ./choc\\Test Set\n",
      "Moved choc_test-set_samples.pkl to ./choc\\Test Set\n",
      "Moved choc_test-set_samples_normalized.pkl to ./choc\\Test Set\n",
      "Moved choc_train-set_labels.pkl to ./choc\\Training Set\n",
      "Moved choc_train-set_labels_normalized.pkl to ./choc\\Training Set\n",
      "Moved choc_train-set_samples.pkl to ./choc\\Training Set\n",
      "Moved choc_train-set_samples_normalized.pkl to ./choc\\Training Set\n",
      "Moved mushrooms_columns.pkl to ./mushrooms\\Test Set\n",
      "Moved mushrooms_model_decisionTree_posttrained.pkl to ./mushrooms\\posttrained\n",
      "Moved mushrooms_model_decisionTree_pretrained.pkl to ./mushrooms\\pretrained\n",
      "Moved mushrooms_model_Gradient_Boosting_posttrained.pkl to ./mushrooms\\posttrained\n",
      "Moved mushrooms_model_Gradient_Boosting_pretrained.pkl to ./mushrooms\\pretrained\n",
      "Moved mushrooms_model_KNN_posttrained.pkl to ./mushrooms\\posttrained\n",
      "Moved mushrooms_model_KNN_pretrained.pkl to ./mushrooms\\pretrained\n",
      "Moved mushrooms_model_MLP_posttrained.pkl to ./mushrooms\\posttrained\n",
      "Moved mushrooms_model_MLP_pretrained.pkl to ./mushrooms\\pretrained\n",
      "Moved mushrooms_model_randomForest_posttrained.pkl to ./mushrooms\\posttrained\n",
      "Moved mushrooms_model_randomForest_pretrained.pkl to ./mushrooms\\pretrained\n",
      "Moved mushrooms_model_SVC_RBF_posttrained.pkl to ./mushrooms\\posttrained\n",
      "Moved mushrooms_model_SVC_RBF_pretrained.pkl to ./mushrooms\\pretrained\n",
      "Moved mushrooms_test-set_labels.pkl to ./mushrooms\\Test Set\n",
      "Moved mushrooms_test-set_labels_normalized.pkl to ./mushrooms\\Test Set\n",
      "Moved mushrooms_test-set_samples.pkl to ./mushrooms\\Test Set\n",
      "Moved mushrooms_test-set_samples_normalized.pkl to ./mushrooms\\Test Set\n",
      "Moved mushrooms_train-set_labels.pkl to ./mushrooms\\Training Set\n",
      "Moved mushrooms_train-set_labels_normalized.pkl to ./mushrooms\\Training Set\n",
      "Moved mushrooms_train-set_samples.pkl to ./mushrooms\\Training Set\n",
      "Moved mushrooms_train-set_samples_normalized.pkl to ./mushrooms\\Training Set\n",
      "Organization complete!\n"
     ]
    }
   ],
   "source": [
    "organize();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2c933",
   "metadata": {},
   "source": [
    "### Test the stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64306cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Decision Tree classifier from 2 datasets\n",
      "Type aligns: True\n",
      "Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "origObj = chocoModels.decisionTree_clf;\n",
    "choco_decisionTree = unpack(constants.filepaths[\"choc_posttrained_decisionTree\"]);\n",
    "print(\"Checking Decision Tree classifier from 2 datasets\");\n",
    "print(f\"Type aligns: {type(origObj) == type(choco_decisionTree)}\");\n",
    "# mushrooms dataset\n",
    "origObj = mushModels.decisionTree_clf;\n",
    "mushrooms_decisionTree = unpack(constants.filepaths[\"mushrooms_posttrained_decisionTree\"]);\n",
    "print(f\"Type aligns: {type(origObj) == type(mushrooms_decisionTree)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5fab77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Gradient Boosting classifier from 2 datasets\n",
      "Type aligns: True\n",
      "Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "origObj = chocoModels.gradientBoost_clf;\n",
    "choco_gradientBoost = unpack(constants.filepaths[\"choc_posttrained_gradientBoost\"]);\n",
    "print(\"Checking Gradient Boosting classifier from 2 datasets\");\n",
    "print(f\"Type aligns: {type(origObj) == type(choco_gradientBoost)}\");\n",
    "# mushrooms dataset\n",
    "origObj = mushModels.gradientBoost_clf;\n",
    "mushrooms_gradientBoost = unpack(constants.filepaths[\"mushrooms_posttrained_gradientBoost\"]);\n",
    "print(f\"Type aligns: {type(origObj) == type(mushrooms_gradientBoost)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9da1646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking KNN classifier from 2 datasets\n",
      "Type aligns: True\n",
      "Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "origObj = chocoModels.knn_clf;\n",
    "choco_KNN = unpack(constants.filepaths[\"choc_posttrained_KNN\"]);\n",
    "print(\"Checking KNN classifier from 2 datasets\");\n",
    "print(f\"Type aligns: {type(origObj) == type(choco_KNN)}\");\n",
    "# mushrooms dataset\n",
    "origObj = mushModels.knn_clf;\n",
    "mushrooms_KNN = unpack(constants.filepaths[\"mushrooms_posttrained_KNN\"]);\n",
    "print(f\"Type aligns: {type(origObj) == type(mushrooms_KNN)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54851ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking KNN classifier from 2 datasets\n",
      "Type aligns: True\n",
      "Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "origObj = chocoModels.mlp_clf;\n",
    "choco_MLP = unpack(constants.filepaths[\"choc_posttrained_MLP\"]);\n",
    "print(\"Checking KNN classifier from 2 datasets\");\n",
    "print(f\"Type aligns: {type(origObj) == type(choco_MLP)}\");\n",
    "# mushrooms dataset\n",
    "origObj = mushModels.mlp_clf;\n",
    "mushrooms_MLP = unpack(constants.filepaths[\"mushrooms_posttrained_MLP\"]);\n",
    "print(f\"Type aligns: {type(origObj) == type(mushrooms_MLP)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20fc95fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking KNN classifier from 2 datasets"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type aligns: True\n",
      "Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "origObj = chocoModels.randomForest_clf;\n",
    "choco_randomForst = unpack(constants.filepaths[\"choc_posttrained_randomForest\"]);\n",
    "print(\"Checking KNN classifier from 2 datasets\");\n",
    "print(f\"Type aligns: {type(origObj) == type(choco_randomForst)}\");\n",
    "# mushrooms dataset\n",
    "origObj = mushModels.randomForest_clf;\n",
    "mushrooms_randomForest = unpack(constants.filepaths[\"mushrooms_posttrained_randomForest\"]);\n",
    "print(f\"Type aligns: {type(origObj) == type(mushrooms_randomForest)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5527d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking SVM classifier from 2 datasets\n",
      "Type aligns: True\n",
      "Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "origObj = chocoModels.svm_clf;\n",
    "choco_SVC = unpack(constants.filepaths[\"choc_posttrained_SVC\"]);\n",
    "print(\"Checking SVM classifier from 2 datasets\");\n",
    "print(f\"Type aligns: {type(origObj) == type(choco_SVC)}\");\n",
    "# mushrooms dataset\n",
    "origObj = mushModels.svm_clf;\n",
    "mushrooms_SVC = unpack(constants.filepaths[\"mushrooms_posttrained_SVC\"]);\n",
    "print(f\"Type aligns: {type(origObj) == type(mushrooms_SVC)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd88da89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking test set labels and samples from Chocolate dataset\n",
      "Samples Array Type aligns: True\n",
      "Labels Array Type aligns: True\n",
      "Checking test set labels and samples from Mushroom dataset\n",
      "Samples Array Type aligns: True\n",
      "Labels Array Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "orig_X_test = choco_X_test;\n",
    "unpack_X_test = unpack(constants.filepaths[\"choc_test-set_samples\"]);\n",
    "print(\"Checking test set labels and samples from Chocolate dataset\");\n",
    "print(f\"Samples Array Type aligns: {type(orig_X_test) == type(unpack_X_test)}\");\n",
    "orig_y_test = choco_y_test;\n",
    "unpack_y_test = unpack(constants.filepaths[\"choc_test-set_labels\"]);\n",
    "print(f\"Labels Array Type aligns: {type(orig_y_test) == type(unpack_y_test)}\");\n",
    "# mushrooms dataset\n",
    "orig_X_test = mush_X_test;\n",
    "unpack_X_test = unpack(constants.filepaths[\"mushrooms_test-set_samples\"]);\n",
    "print(\"Checking test set labels and samples from Mushroom dataset\");\n",
    "print(f\"Samples Array Type aligns: {type(orig_X_test) == type(unpack_X_test)}\");\n",
    "orig_y_test = mush_y_test;\n",
    "unpack_y_test = unpack(constants.filepaths[\"mushrooms_test-set_labels\"]);\n",
    "print(f\"Labels Array Type aligns: {type(orig_y_test) == type(unpack_y_test)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b53e7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training set labels and samples from Chocolate dataset\n",
      "Samples Array Type aligns: True\n",
      "Labels Array Type aligns: True\n",
      "Checking training set labels and samples from Mushroom dataset\n",
      "Samples Array Type aligns: True\n",
      "Labels Array Type aligns: True\n"
     ]
    }
   ],
   "source": [
    "# choc dataset\n",
    "orig_X_train = choco_X_train;\n",
    "unpack_X_train = unpack(constants.filepaths[\"choc_train-set_samples\"]);\n",
    "print(\"Checking training set labels and samples from Chocolate dataset\");\n",
    "print(f\"Samples Array Type aligns: {type(orig_X_train) == type(unpack_X_train)}\");\n",
    "orig_y_train = choco_y_test;\n",
    "unpack_y_train = unpack(constants.filepaths[\"choc_train-set_labels\"]);\n",
    "print(f\"Labels Array Type aligns: {type(orig_y_train) == type(unpack_y_train)}\");\n",
    "# mushrooms dataset\n",
    "orig_X_train = mush_X_train;\n",
    "unpack_X_train = unpack(constants.filepaths[\"mushrooms_train-set_samples\"]);\n",
    "print(\"Checking training set labels and samples from Mushroom dataset\");\n",
    "print(f\"Samples Array Type aligns: {type(orig_X_train) == type(unpack_X_train)}\");\n",
    "orig_y_train = mush_y_train;\n",
    "unpack_y_train = unpack(constants.filepaths[\"mushrooms_train-set_labels\"]);\n",
    "print(f\"Labels Array Type aligns: {type(orig_y_train) == type(unpack_y_train)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca09eb9",
   "metadata": {},
   "source": [
    "We have made sure that all the data are dumped to .pkl files (and unpacked) accurately. Therefore, we can proceed with performance evaluation on another notebook called `CSI5155 Assignment 1 Evaluation Part - Kelvin Mock 300453668.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
