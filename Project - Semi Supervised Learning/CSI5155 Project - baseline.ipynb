{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning - Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to perform supervised learning on a particular classifier from assignment 1 to construct a baseline model for the semi-supervised learning. See the Gradient Boosting model handled in `CSI5155 Assignment 1 Modelling Part- Kelvin Mock 300453668.ipynb` (assignment 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import os;\n",
    "import sys;\n",
    "import joblib;\n",
    "import random;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "# importing custom modules\n",
    "sys.path.append(\"../Assignment 1 - Model Comparison/\");\n",
    "from fileOrganizer import unpack, organize;\n",
    "import constants;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in a sample:  ['age' 'gender' 'education' 'country' 'ethnicity' 'nscore' 'escore'\n",
      " 'oscore' 'ascore' 'cscore' 'impuslive' 'ss']\n"
     ]
    }
   ],
   "source": [
    "columns = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.COLUMNS_DIR,\n",
    "    constants.COLUMNS_FILENAME\n",
    "));\n",
    "print(\"Columns in a sample: \", columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We load the original samples and labels array from the training set and test set respectively. The data are stratified during the split in assignment 1. The size of the test set is of the ratio 1/3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Training Set:  1256\n",
      "Number of Features in Training Set:  12\n",
      "Value range of the original Training Set:  -3.46436 3.46436\n"
     ]
    }
   ],
   "source": [
    "mush_X_train = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.X_TRAIN_FILENAME\n",
    "));\n",
    "print(\"Number of Samples in Training Set: \", len(mush_X_train));\n",
    "print(\"Number of Features in Training Set: \", len(mush_X_train[random.randint(0, len(mush_X_train)-1)]));\n",
    "print(\"Value range of the original Training Set: \", np.min(mush_X_train), np.max(mush_X_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Training Set:  1256\n",
      "Unique Labels in Training Set:  ['non-user' 'user']\n"
     ]
    }
   ],
   "source": [
    "mush_y_train = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_FILENAME\n",
    "));\n",
    "print(\"Number of Samples in Training Set: \", len(mush_y_train));\n",
    "print(\"Unique Labels in Training Set: \", np.unique(mush_y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Testing Set:  629\n",
      "Number of Features in Testing Set:  12\n",
      "Value range of the original Testing Set:  -3.27393 3.27393\n"
     ]
    }
   ],
   "source": [
    "mush_X_test = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TEST_DIR,\n",
    "    constants.X_TEST_FILENAME\n",
    "));\n",
    "print(\"Number of Samples in Testing Set: \", len(mush_X_test));\n",
    "print(\"Number of Features in Testing Set: \", len(mush_X_test[random.randint(0, len(mush_X_test)-1)]));\n",
    "print(\"Value range of the original Testing Set: \", np.min(mush_X_test), np.max(mush_X_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Testing Set:  629\n",
      "Unique Labels in Testing Set:  ['non-user' 'user']\n"
     ]
    }
   ],
   "source": [
    "mush_y_test = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TEST_DIR,\n",
    "    constants.Y_TEST_FILENAME\n",
    "));\n",
    "print(\"Number of Samples in Testing Set: \", len(mush_y_test));\n",
    "print(\"Unique Labels in Testing Set: \", np.unique(mush_y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading also the Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normalized Samples in Training Set:  1256\n",
      "Number of Features in the Normalized Training Set:  12\n",
      "Value range of the original Training Set:  -4.827248760778992 13.457018899436779\n"
     ]
    }
   ],
   "source": [
    "mush_X_train_norm = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.X_TRAIN_NORMALIZED_FILENAME\n",
    "));\n",
    "print(\"Number of Normalized Samples in Training Set: \", len(mush_X_train_norm));\n",
    "print(\"Number of Features in the Normalized Training Set: \", len(mush_X_train_norm[random.randint(0, len(mush_X_train_norm)-1)]));\n",
    "print(\"Value range of the original Training Set: \", np.min(mush_X_train_norm), np.max(mush_X_train_norm));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Training Set:  1256\n",
      "Unique Labels in Training Set:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "mush_y_train_norm = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_NORMALIZED_FILENAME\n",
    "));\n",
    "print(\"Number of Samples in Training Set: \", len(mush_y_train_norm));\n",
    "print(\"Unique Labels in Training Set: \", np.unique(mush_y_train_norm));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normalized Samples in Testing Set:  629\n",
      "Number of Features in the Normalized Testing Set:  12\n",
      "Value range of the Normalized Testing Set:  -4.827248760778992 13.457018899436779\n"
     ]
    }
   ],
   "source": [
    "mush_X_test_norm = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TEST_DIR,\n",
    "    constants.X_TEST_NORMALIZED_FILENAME\n",
    "));\n",
    "print(\"Number of Normalized Samples in Testing Set: \", len(mush_X_test_norm));\n",
    "print(\"Number of Features in the Normalized Testing Set: \", len(mush_X_test_norm[random.randint(0, len(mush_X_test_norm)-1)]));\n",
    "print(\"Value range of the Normalized Testing Set: \", np.min(mush_X_test_norm), np.max(mush_X_test_norm));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples in Testing Set:  629\n",
      "Unique Labels in Testing Set:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "mush_y_test_norm = joblib.load(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.TEST_DIR,\n",
    "    constants.Y_TEST_NORMALIZED_FILENAME\n",
    "));\n",
    "print(\"Number of Samples in Testing Set: \", len(mush_y_test_norm));\n",
    "print(\"Unique Labels in Testing Set: \", np.unique(mush_y_test_norm));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We load the trained version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: array([ 6,  8,  4, 14, 12,  9,  9,  3,  7, 17, 19,  1, 19, 17, 15, 12, 16,\n",
       "       18,  2,  8, 15,  9, 12,  2,  8, 17, 11,  1, 14, 15, 13,  4,  1, 19,\n",
       "       12, 15,  6, 19,  9, 17, 10, 12, 16,  3,  5, 13, 10, 19,  5,  5,  4,\n",
       "       10,  6,  4,  5,  2, 17,  1,  1,  5, 10,  1, 10, 11,  8, 14, 13, 12,\n",
       "        8, 17, 14,  1,  3,  4, 19, 10,  6, 19, 14,  2, 19, 15, 13,  7,  5,\n",
       "        3,  4,  3, 14, 10,  5, 16, 10,  5, 16, 15,  4,  8, 17,  8],\n",
       "      dtype=int64),\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002C01AEF09D0&gt;},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: array([ 6,  8,  4, 14, 12,  9,  9,  3,  7, 17, 19,  1, 19, 17, 15, 12, 16,\n",
       "       18,  2,  8, 15,  9, 12,  2,  8, 17, 11,  1, 14, 15, 13,  4,  1, 19,\n",
       "       12, 15,  6, 19,  9, 17, 10, 12, 16,  3,  5, 13, 10, 19,  5,  5,  4,\n",
       "       10,  6,  4,  5,  2, 17,  1,  1,  5, 10,  1, 10, 11,  8, 14, 13, 12,\n",
       "        8, 17, 14,  1,  3,  4, 19, 10,  6, 19, 14,  2, 19, 15, 13,  7,  5,\n",
       "        3,  4,  3, 14, 10,  5, 16, 10,  5, 16, 15,  4,  8, 17,  8],\n",
       "      dtype=int64),\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002C01AEF09D0&gt;},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
       "                   param_distributions={'max_depth': array([ 6,  8,  4, 14, 12,  9,  9,  3,  7, 17, 19,  1, 19, 17, 15, 12, 16,\n",
       "       18,  2,  8, 15,  9, 12,  2,  8, 17, 11,  1, 14, 15, 13,  4,  1, 19,\n",
       "       12, 15,  6, 19,  9, 17, 10, 12, 16,  3,  5, 13, 10, 19,  5,  5,  4,\n",
       "       10,  6,  4,  5,  2, 17,  1,  1,  5, 10,  1, 10, 11,  8, 14, 13, 12,\n",
       "        8, 17, 14,  1,  3,  4, 19, 10,  6, 19, 14,  2, 19, 15, 13,  7,  5,\n",
       "        3,  4,  3, 14, 10,  5, 16, 10,  5, 16, 15,  4,  8, 17,  8],\n",
       "      dtype=int64),\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002C01AEF09D0>},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boost (Trained)\n",
    "supervisedModel = unpack(os.path.join(\n",
    "    os.pardir,\n",
    "    constants.ASM1_DIR,\n",
    "    constants.MUSH_DIR,\n",
    "    constants.POSTTRAINED_DIR,\n",
    "    constants.MODEL_FILENAME\n",
    "));\n",
    "supervisedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Datasets into Labelled and Unlabelled sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We use normalized data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labelled Samples:  1004\n",
      "Number of Unlabelled Samples:  252\n",
      "Number of Features in Labelled Samples:  12\n",
      "Number of Features in Unlabelled Samples:  12\n",
      "Value range of the Labelled Samples:  -4.827248760778992 13.457018899436779\n",
      "Value range of the Unlabelled Samples:  -4.827248760778992 13.457018899436779\n",
      "Unique Labels in Labelled Samples:  [0 1]\n",
      "Unique Labels in Unlabelled Samples:  [0 1]\n",
      "Size of a random sample from Labelled Samples:  [ 0.53976709 -1.01282104 -1.50814511  0.85971296  2.58176576  1.40407638\n",
      " -0.16659083 -0.31245393 -0.29490312 -0.66066986 -0.20693561  0.1016611 ]\n"
     ]
    }
   ],
   "source": [
    "X_train_labelled,  X_trained_unlabelled, y_train_labelled, y_train_unlabelled = train_test_split(\n",
    "    mush_X_train_norm,\n",
    "    mush_y_train_norm,\n",
    "    test_size=constants.LABELLED_PORTION,\n",
    "    random_state=constants.RANDOM_STATE\n",
    ")\n",
    "print(\"Number of Labelled Samples: \", len(X_train_labelled));\n",
    "print(\"Number of Unlabelled Samples: \", len(X_trained_unlabelled));\n",
    "print(\"Number of Features in Labelled Samples: \", len(X_train_labelled[random.randint(0, len(X_train_labelled))]));\n",
    "print(\"Number of Features in Unlabelled Samples: \", len(X_trained_unlabelled[random.randint(0, len(X_trained_unlabelled))]));\n",
    "print(\"Value range of the Labelled Samples: \", np.min(X_train_labelled), np.max(X_train_labelled));\n",
    "print(\"Value range of the Unlabelled Samples: \", np.min(X_trained_unlabelled), np.max(X_trained_unlabelled));\n",
    "print(\"Unique Labels in Labelled Samples: \", np.unique(y_train_labelled));\n",
    "print(\"Unique Labels in Unlabelled Samples: \", np.unique(y_train_unlabelled));\n",
    "print(\"Size of a random sample from Labelled Samples: \", X_train_labelled[random.randint(0, len(X_train_labelled))]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model with Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisedModel.fit(X_train_labelled, y_train_labelled);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Pseudo-Labels for Unlabelled Data from Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Predictions:  252\n",
      "Unique Labels in Predictions:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_unlabelled = supervisedModel.predict(X_trained_unlabelled);\n",
    "print(\"Number of Predictions: \", len(y_pred_unlabelled));\n",
    "print(\"Unique Labels in Predictions: \", np.unique(y_pred_unlabelled));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Baseline Model and Related Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model (trained with labelled data) in the current project directory\n",
    "if (constants.MODEL_DIR not in os.listdir(os.curdir)):\n",
    "    os.mkdir(constants.MODEL_DIR);\n",
    "joblib.dump(supervisedModel, os.path.join(\n",
    "    constants.MODEL_DIR,\n",
    "    constants.MODEL_FILENAME\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the original training set data in the current project directory\n",
    "if (constants.TRAIN_DIR not in os.listdir(os.curdir)):\n",
    "    os.mkdir(constants.TRAIN_DIR);\n",
    "# original training set\n",
    "joblib.dump(mush_X_train, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.X_TRAIN_FILENAME\n",
    "));\n",
    "joblib.dump(mush_y_train, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_FILENAME\n",
    "));\n",
    "# normalized training set\n",
    "joblib.dump(mush_X_train_norm, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.X_TRAIN_NORMALIZED_FILENAME\n",
    "));\n",
    "joblib.dump(mush_y_train_norm, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_NORMALIZED_FILENAME\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the original testing set data in the current project directory\n",
    "if (constants.TEST_DIR not in os.listdir(os.curdir)):\n",
    "    os.mkdir(constants.TEST_DIR);\n",
    "# original testing set\n",
    "joblib.dump(mush_X_test, os.path.join(\n",
    "    constants.TEST_DIR,\n",
    "    constants.X_TEST_FILENAME\n",
    "));\n",
    "joblib.dump(mush_y_test, os.path.join(\n",
    "    constants.TEST_DIR,\n",
    "    constants.Y_TEST_FILENAME\n",
    "));\n",
    "# normalized testing set\n",
    "joblib.dump(mush_X_test_norm, os.path.join(\n",
    "    constants.TEST_DIR,\n",
    "    constants.X_TEST_NORMALIZED_FILENAME\n",
    "));\n",
    "joblib.dump(mush_y_test_norm, os.path.join(\n",
    "    constants.TEST_DIR,\n",
    "    constants.Y_TEST_NORMALIZED_FILENAME\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the column names in the current project directory\n",
    "if (constants.COLUMNS_DIR not in os.listdir(os.curdir)):\n",
    "    os.mkdir(constants.COLUMNS_DIR);\n",
    "joblib.dump(columns, os.path.join(\n",
    "    constants.COLUMNS_DIR,\n",
    "    constants.COLUMNS_FILENAME\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data after split\n",
    "# labelled data\n",
    "joblib.dump(X_train_labelled, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.X_TRAIN_LABELLED_FILENAME\n",
    "));\n",
    "joblib.dump(y_train_labelled, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_LABELLED_FILENAME\n",
    "));\n",
    "# unlabeled data\n",
    "joblib.dump(X_trained_unlabelled, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.X_TRAIN_UNLABELLED_FILENAME\n",
    "));\n",
    "joblib.dump(y_train_unlabelled, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_UNLABELLED_FILENAME\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unlabelled predictions as pseudo-labels\n",
    "joblib.dump(y_pred_unlabelled, os.path.join(\n",
    "    constants.TRAIN_DIR,\n",
    "    constants.Y_TRAIN_PSEUDO_FILENAME\n",
    "));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
